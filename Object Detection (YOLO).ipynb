{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497e703-2a6e-4ef8-9896-aace437db5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code detects objects using the YOLO algorithm. You may need to install the ultralytics library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b71250-1fe3-4dae-bb8e-641923772c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6399b46-002d-4289-981b-ca41e4c43a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e25c64-7fe2-4fdf-a480-a117547a89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m.pt\")\n",
    "#YOLOv8 is a group of neural network models.\n",
    "#The bigger the model you choose, the better the prediction quality you can achieve, but the slower it will work.\n",
    "#It will download the yolov8m.pt file from the Ultralytics server to the current folder. Then it will construct the model object. \n",
    "#Now you can train this model, detect objects, and export it to use in production.\n",
    "\n",
    "#All YOLOv8 models for object detection ship already pre-trained on the COCO dataset, which is a huge collection of images of 80 different types. So, if you do not have specific needs, then you can just run it as is, without additional training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42337c-c216-4ef7-9828-17cd49bc4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(\"195.jpg\") #it returns an array with a single item. You can pass multiple images. \n",
    "#Make sure you use the correct directory. My image is under the same path as my notebook.\n",
    "result = results[0] #The result contains detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e994809-da2e-4828-9468-9678ca5b574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image with predictions\n",
    "annotated_image = result.plot()\n",
    "plt.imshow(annotated_image)\n",
    "plt.axis('off')  # Turn off the axes for better visualization\n",
    "plt.show()\n",
    "\n",
    "#The code below saves the image with annotations:\n",
    "# Convert the NumPy array to a PIL Image\n",
    "annotated_image_pil = Image.fromarray(annotated_image)\n",
    "\n",
    "# Save the PIL Image\n",
    "annotated_image_pil.save(\"detected_objects_195.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609ea46-55c2-41f9-8cb2-cda52f759acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The most important one is the boxes array with information about detected bounding boxes on the image. You can determine how many objects it detected by running the len function\n",
    "len(result.boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6c90c-b033-4687-889d-55f72bf386ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.names) #This dictionary has everything that this model can detect. \n",
    "#Recall that there are 80 classes. It assigns 0 or close to 0 probabilities for those classes which are not in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8788c6-4ecb-4c28-b1d3-f893235b61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can analyze each box either in a loop or manually.\n",
    "box = result.boxes[0]\n",
    "print(\"Object type:\", box.cls)\n",
    "print(\"Coordinates:\", box.xyxy)\n",
    "print(\"Probability:\", box.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c76572-5611-40a3-9496-71539d65d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us get the \"actual\" data\n",
    "cords = box.xyxy[0].tolist()\n",
    "cords = [round(x) for x in cords]\n",
    "class_id = result.names[box.cls[0].item()]\n",
    "conf = round(box.conf[0].item(), 2)\n",
    "print(\"Object type:\", class_id)\n",
    "print(\"Coordinates:\", cords)\n",
    "print(\"Probability:\", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f3231-936b-4aca-b84d-6475eb6e850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in result.boxes:\n",
    "  class_id = result.names[box.cls[0].item()]\n",
    "  cords = box.xyxy[0].tolist()\n",
    "  cords = [round(x) for x in cords]\n",
    "  conf = round(box.conf[0].item(), 2)\n",
    "  print(\"Object type:\", class_id) #the ID of object type\n",
    "  print(\"Coordinates:\", cords) #the coordinates of the box as an array [x1,y1,x2,y2]\n",
    "  print(\"Probability:\", conf) #the confidence level (probability) of the model about this object using classification. If it's very low, you can ignore.\n",
    "  print(\"\\nNext Object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8d0d0-b7ba-4bae-a16b-319e327c9ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
